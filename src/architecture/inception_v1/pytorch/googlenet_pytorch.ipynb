{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "googlenet_pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEsCk4Nw6Ca3",
        "colab_type": "text"
      },
      "source": [
        "# I) Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbsdYWQ36CbD",
        "colab_type": "text"
      },
      "source": [
        "- The paper [Going Deeper with Convolutions][paper] introduces the first version of Inception model called GoogLeNet.\n",
        "\n",
        "\n",
        "- During ILSVLC-2014, they achieved 1st place at the classification task (top-5 test error = 6.67%)\n",
        "\n",
        "\n",
        "- It has around 6.7977 million parameters (without auxilaries layers) which is 9x fewer than AlexNet (ILSVRC-2012 winner) and 20x fewer than its competitor VGG-16.\n",
        "\n",
        "\n",
        "- In most of the standard network architectures, the intuition is not clear why and when to perform the max-pooling operation, when to use the convolutional operation. For example, in AlextNet we have the convolutional operation and max-pooling operation following each other whereas in VGGNet, we have 3 convolutional operations in a row and then 1 max-pooling layer.\n",
        "\n",
        "\n",
        "- Thus, **the idea behind GoogLeNet is to use all the operations at the same time**. It computes multiple kernels of different size over the same input map in parallel, concatenating their results into a single output. This is called an **Inception module**.\n",
        "\n",
        "<div style=\"text-align: center\">\n",
        "    <img src=\"https://cdn.discordapp.com/attachments/676833120053493770/689776141221101629/unknown.png\"\n",
        "         height=\"100%\" width=\"100%\">\n",
        "</div>\n",
        "\n",
        "- Consider the following:\n",
        "\n",
        "<div style=\"text-align: center\">\n",
        "    <img src=\"https://media.discordapp.net/attachments/676833120053493770/690136206092402715/unknown.png\"\n",
        "         height=\"50%\" width=\"70%\">\n",
        "</div>\n",
        " \n",
        "\n",
        "<div style=\"text-align: center\">\n",
        "    <img src=\"https://cdn.discordapp.com/attachments/676833120053493770/690138280058028146/unknown.png\"\n",
        "         height=\"50%\" width=\"90%\">\n",
        "</div>\n",
        "\n",
        "\n",
        "- The Naive approach is computationally expensive:\n",
        "    - Computation cost = ((28 x 28 x 5 x 5) x 192) x 32 $\\simeq$ **120 Mil**\n",
        "        - We perform (28 x 28 x 5 x 5) operations along 192 channels for each of the 32 filters.\n",
        "\n",
        "\n",
        "- The dimension reduction approach is **less** computationally expensive:\n",
        "    - 1st layer computation cost = ((28 x 28 x 1 x 1) x 192) x 16 $\\simeq$ 2.4 Mil\n",
        "    - 2nd layer computation cost = ((28 x 28 x 5 x 5) x 16) x 32 $\\simeq$ 10 Mil  \n",
        "    - Total computation cost $\\simeq$ **12.4 Mil**\n",
        "\n",
        "---\n",
        "\n",
        "Here its architecture:\n",
        "\n",
        "<div style=\"text-align: center\">\n",
        "    <img src=\"https://cdn.discordapp.com/attachments/676833120053493770/690150147392667651/unknown.png\"\n",
        "         height=\"100%\" width=\"100%\">\n",
        "</div>\n",
        "\n",
        "- There are:\n",
        "    - 9 Inception modules (red box)\n",
        "    - Global Average pooling were used instead of a Fully-connected layer.\n",
        "        - It enables adapting and fine-tuning on the network easily.\n",
        "    - 2 auxilaries softmax layer (green box)\n",
        "        - Their role is to push the network toward its goal and helps to ensure that the intermediate features are good enough for the network to learn.\n",
        "        - It turns out that softmax0 and sofmax1 gives regularization effect.\n",
        "        - During training, their loss gets added to the total loss with a discount weight (the losses of the auxiliary classifiers were weighted by 0.3).\n",
        "        - During inference, they are discarded.\n",
        "        - Structure:\n",
        "            - Average pooling layer with 5Ã—5 filter size and stride 3 resulting in an output size:\n",
        "                - For 1st green box: 4x4x512.\n",
        "                - For 2nd green box: 4x4x528.\n",
        "            - 128 1x1 convolutions + ReLU.\n",
        "            - Fully-connected layer with 1024 units + ReLU.\n",
        "            - Dropout = 70%.\n",
        "            - Linear layer (1000 classes) + Softmax.\n",
        "\n",
        "<br>\n",
        "\n",
        "<div style=\"text-align: center\">\n",
        "    <img src=\"https://cdn.discordapp.com/attachments/676833120053493770/690147584534511659/unknown.png\"\n",
        "         height=\"100%\" width=\"80%\">\n",
        "</div>\n",
        "\n",
        "<div style=\"text-align: center\">\n",
        "    <img src=\"https://cdn.discordapp.com/attachments/676833120053493770/690676447336988832/legend.png\"\n",
        "         height=\"100%\" width=\"100%\">\n",
        "</div>\n",
        "\n",
        "<div style=\"text-align: center\">\n",
        "    <img src=\"https://cdn.discordapp.com/attachments/676833120053493770/691604662268461056/unknown.png\"\n",
        "         height=\"100%\" width=\"100%\">\n",
        "</div>\n",
        "\n",
        "<div style=\"text-align: center\">\n",
        "    <img src=\"https://cdn.discordapp.com/attachments/676833120053493770/691591126502866944/unknown.png\"\n",
        "         height=\"100%\" width=\"100%\">\n",
        "</div>\n",
        "\n",
        "[paper]: https://arxiv.org/pdf/1409.4842.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAnJNzC26CbL",
        "colab_type": "text"
      },
      "source": [
        "# II) Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thwqjGZx6CbQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from utils import *\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import urllib.request\n",
        "import scipy.stats as stats\n",
        "from collections import OrderedDict\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms, datasets\n",
        "from torchsummary import summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ye16dpM6Cbk",
        "colab_type": "text"
      },
      "source": [
        "## a) Loading dataset / Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZxwkL6z6Cb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_cifar():\n",
        "    \n",
        "    transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                    transforms.Normalize(mean=[0.5], std=[0.5])])\n",
        "            \n",
        "    train_dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transform)\n",
        "    test_dataset = datasets.CIFAR10('./data', train=False, download=True, transform=transform)\n",
        "\n",
        "    #Clear downloading message.\n",
        "    clear_output()\n",
        "    \n",
        "    # Split dataset into training set and validation set.\n",
        "    train_dataset, val_dataset = random_split(train_dataset, (45000, 5000))\n",
        "    \n",
        "    print(\"Image Shape: {}\".format(train_dataset[0][0].numpy().shape), end = '\\n\\n')\n",
        "    print(\"Training Set:   {} samples\".format(len(train_dataset)))\n",
        "    print(\"Validation Set:   {} samples\".format(len(val_dataset)))\n",
        "    print(\"Test Set:       {} samples\".format(len(test_dataset)))\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "      BATCH_SIZE = 4096\n",
        "    else:\n",
        "      BATCH_SIZE = 32\n",
        "\n",
        "    # Create iterator.\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)\n",
        "    \n",
        "    # Delete the data/ folder.\n",
        "    shutil.rmtree('./data')\n",
        "    \n",
        "    return train_loader, val_loader, test_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpQx_0oy6CcD",
        "colab_type": "code",
        "outputId": "b13251eb-5c21-45b0-8c21-84e800fdbd86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "train_loader, val_loader, test_loader = load_cifar()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Image Shape: (3, 32, 32)\n",
            "\n",
            "Training Set:   45000 samples\n",
            "Validation Set:   5000 samples\n",
            "Test Set:       10000 samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN8-wqGY6CcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_example(X, y, y_pred=None):\n",
        "    \"\"\"\n",
        "        Plots 9 examples and their associate labels.\n",
        "        \n",
        "        Parameters:\n",
        "        -X: Training examples.\n",
        "        -y: true labels.\n",
        "        -y_pred: predicted labels.\n",
        "    \"\"\"\n",
        "    classes = {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer',\n",
        "               5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck'}\n",
        "    \n",
        "    # Create figure with 3 x 3 sub-plots.\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(10,10))\n",
        "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
        "     \n",
        "    X, y = X[:9, 0, ...], y[:9] \n",
        "    \n",
        "    for i, ax in enumerate(axes.flat):\n",
        "        # Plot image.\n",
        "        ax.imshow(X[i])\n",
        "\n",
        "        # Show true and predicted classes.\n",
        "        if y_pred is None:\n",
        "            xlabel = \"True: {0}\".format(classes[y[i]])\n",
        "        else:\n",
        "            xlabel = \"True: {0}, Pred: {1}\".format(classes[y[i]], classes[y_pred[i]])\n",
        "\n",
        "        # Show the classes as the label on the x-axis.\n",
        "        ax.set_xlabel(xlabel)\n",
        "        \n",
        "        # Remove ticks from the plot.\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "    \n",
        "    # Ensure the plot is shown correctly with multiple plots in a single Notebook cell.\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fmsgZ6s6Ccc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_example_errors(X, y, y_pred):\n",
        "    \"\"\"\n",
        "        Plots 9 example errors and their associate true/predicted labels.\n",
        "        \n",
        "        Parameters:\n",
        "        -X: Training examples.\n",
        "        -y: true labels.\n",
        "        -y_pred: predicted labels.\n",
        "    \n",
        "    \"\"\"\n",
        "    incorrect = (y != y_pred)\n",
        " \n",
        "    X = X[incorrect]\n",
        "    y = y[incorrect]\n",
        "    y_pred = y_pred[incorrect]\n",
        "\n",
        "    # Plot the first 9 images.\n",
        "    plot_example(X, y, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2ixWOVN6Cco",
        "colab_type": "code",
        "outputId": "168b0290-8111-49f8-b20d-89bd8f97a52c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "source": [
        "images, labels = iter(train_loader).next()\n",
        "plot_example(images.numpy(), labels.numpy())"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAI8CAYAAAAX02rjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x720 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByGkcE0j6Cc2",
        "colab_type": "text"
      },
      "source": [
        "## b) Architecture build"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6jYC55V6Cc6",
        "colab_type": "text"
      },
      "source": [
        "- Local Response Normalization will be replaced by Batch Normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk3QXQjL6Cc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        \n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.act = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.act(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBqQN88P6CdH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InceptionModule(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_channels, f_1x1, f_3x3_r, f_3x3, f_5x5_r, f_5x5, f_pp):\n",
        "        super(InceptionModule, self).__init__()\n",
        "        \n",
        "        self.branch1 = nn.Sequential(\n",
        "            ConvBlock(in_channels, f_1x1, kernel_size=1, stride=1, padding=0)\n",
        "        )\n",
        "        \n",
        "        self.branch2 = nn.Sequential(\n",
        "            ConvBlock(in_channels, f_3x3_r, kernel_size=1, stride=1, padding=0),\n",
        "            ConvBlock(f_3x3_r, f_3x3, kernel_size=3, stride=1, padding=1)\n",
        "        )\n",
        "        \n",
        "        self.branch3 = nn.Sequential(\n",
        "            ConvBlock(in_channels, f_5x5_r, kernel_size=1, stride=1, padding=0),\n",
        "            ConvBlock(f_5x5_r, f_5x5, kernel_size=5, stride=1, padding=2)\n",
        "        )\n",
        "        \n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(3, stride=1, padding=1, ceil_mode=True),\n",
        "            ConvBlock(in_channels, f_pp, kernel_size=1, stride=1, padding=0)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        branch1 = self.branch1(x)\n",
        "        branch2 = self.branch2(x)\n",
        "        branch3 = self.branch3(x)\n",
        "        branch4 = self.branch4(x)\n",
        "        \n",
        "        return torch.cat([branch1, branch2, branch3, branch4], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIlaEO6b6CdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InceptionAux(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(InceptionAux, self).__init__()\n",
        "        \n",
        "        self.pool = nn.AdaptiveAvgPool2d((4,4))\n",
        "        self.conv = nn.Conv2d(in_channels, 128, kernel_size=1, stride=1, padding=0)\n",
        "        self.act = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(2048, 1024)\n",
        "        self.dropout = nn.Dropout(0.7)\n",
        "        self.fc2 = nn.Linear(1024, num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = self.conv(x)\n",
        "        x = self.act(x)\n",
        "    \n",
        "        x = torch.flatten(x, 1)\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az-c6q6i6Cde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GoogLeNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, isTraining, num_classes = 10, init_weights=True):\n",
        "        super(GoogLeNet, self).__init__()\n",
        "        \n",
        "        self.isTraining = isTraining\n",
        "        \n",
        "        self.conv1 = ConvBlock(3, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.pool1 = nn.MaxPool2d(3, stride=2, padding=0, ceil_mode=True)\n",
        "        self.conv2 = ConvBlock(64, 64, kernel_size=1, stride=1, padding=0)\n",
        "        self.conv3 = ConvBlock(64, 192, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool3 = nn.MaxPool2d(3, stride=2, padding=0, ceil_mode=True)\n",
        "        self.inception3A = InceptionModule(in_channels=192,\n",
        "                                           f_1x1=64,\n",
        "                                           f_3x3_r=96,\n",
        "                                           f_3x3=128,\n",
        "                                           f_5x5_r=16,\n",
        "                                           f_5x5=32,\n",
        "                                           f_pp=32)\n",
        "        self.inception3B = InceptionModule(in_channels=256,\n",
        "                                           f_1x1=128,\n",
        "                                           f_3x3_r=128,\n",
        "                                           f_3x3=192,\n",
        "                                           f_5x5_r=32,\n",
        "                                           f_5x5=96,\n",
        "                                           f_pp=64)\n",
        "        self.pool4 = nn.MaxPool2d(3, stride=2, padding=0, ceil_mode=True)\n",
        "        self.inception4A = InceptionModule(in_channels=480,\n",
        "                                           f_1x1=192,\n",
        "                                           f_3x3_r=96,\n",
        "                                           f_3x3=208,\n",
        "                                           f_5x5_r=16,\n",
        "                                           f_5x5=48,\n",
        "                                           f_pp=64)\n",
        "        self.inception4B = InceptionModule(in_channels=512,\n",
        "                                           f_1x1=160,\n",
        "                                           f_3x3_r=112,\n",
        "                                           f_3x3=224,\n",
        "                                           f_5x5_r=24,\n",
        "                                           f_5x5=64,\n",
        "                                           f_pp=64)\n",
        "        self.inception4C = InceptionModule(in_channels=512,\n",
        "                                           f_1x1=128,\n",
        "                                           f_3x3_r=128,\n",
        "                                           f_3x3=256,\n",
        "                                           f_5x5_r=24,\n",
        "                                           f_5x5=64,\n",
        "                                           f_pp=64)\n",
        "        self.inception4D = InceptionModule(in_channels=512,\n",
        "                                           f_1x1=112,\n",
        "                                           f_3x3_r=144,\n",
        "                                           f_3x3=288,\n",
        "                                           f_5x5_r=32,\n",
        "                                           f_5x5=64,\n",
        "                                           f_pp=64)\n",
        "        self.inception4E = InceptionModule(in_channels=528,\n",
        "                                           f_1x1=256,\n",
        "                                           f_3x3_r=160,\n",
        "                                           f_3x3=320,\n",
        "                                           f_5x5_r=32,\n",
        "                                           f_5x5=128,\n",
        "                                           f_pp=128)\n",
        "        self.pool5 = nn.MaxPool2d(3, stride=2, padding=0, ceil_mode=True)\n",
        "        self.inception5A = InceptionModule(in_channels=832,\n",
        "                                           f_1x1=256,\n",
        "                                           f_3x3_r=160,\n",
        "                                           f_3x3=320,\n",
        "                                           f_5x5_r=32,\n",
        "                                           f_5x5=128,\n",
        "                                           f_pp=128)\n",
        "        self.inception5B = InceptionModule(in_channels=832,\n",
        "                                           f_1x1=384,\n",
        "                                           f_3x3_r=192,\n",
        "                                           f_3x3=384,\n",
        "                                           f_5x5_r=48,\n",
        "                                           f_5x5=128,\n",
        "                                           f_pp=128)\n",
        "        self.pool6 = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.dropout = nn.Dropout(0.4)\n",
        "        self.fc = nn.Linear(1024, num_classes)\n",
        "        \n",
        "        if self.isTraining:   \n",
        "            self.aux4A = InceptionAux(512, num_classes) \n",
        "            self.aux4D = InceptionAux(528, num_classes)\n",
        "        \n",
        "        if init_weights:\n",
        "            self._initialize_weights()\n",
        "    \n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                X = stats.truncnorm(-2, 2, scale=0.01)\n",
        "                values = torch.as_tensor(X.rvs(m.weight.numel()), dtype=m.weight.dtype)\n",
        "                values = values.view(m.weight.size())\n",
        "                with torch.no_grad():\n",
        "                    m.weight.copy_(values)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.pool3(x)\n",
        "        x = self.inception3A(x)\n",
        "        x = self.inception3B(x)\n",
        "        x = self.pool4(x)\n",
        "        x = self.inception4A(x)\n",
        "        \n",
        "        if self.isTraining:\n",
        "            aux1 = self.aux4A(x)\n",
        "        \n",
        "        x = self.inception4B(x)\n",
        "        x = self.inception4C(x)\n",
        "        x = self.inception4D(x)\n",
        "        \n",
        "        if self.isTraining:\n",
        "            aux2 = self.aux4D(x)\n",
        "        \n",
        "        x = self.inception4E(x)\n",
        "        x = self.pool5(x)\n",
        "        x = self.inception5A(x)\n",
        "        x = self.inception5B(x)\n",
        "        x = self.pool6(x)\n",
        "        x = torch.flatten(x,1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        \n",
        "        if self.isTraining:\n",
        "            return x, aux1, aux2\n",
        "        else:\n",
        "            return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tHvaMkB26Cdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = GoogLeNet(isTraining=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "w_Iwek5h6Cdx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "03a1ba27-f22f-4a8a-8991-ce08c8358ca3"
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "model.to(device)\n",
        "summary(model, (3, 32, 32))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 16, 16]           9,472\n",
            "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
            "              ReLU-3           [-1, 64, 16, 16]               0\n",
            "         ConvBlock-4           [-1, 64, 16, 16]               0\n",
            "         MaxPool2d-5             [-1, 64, 8, 8]               0\n",
            "            Conv2d-6             [-1, 64, 8, 8]           4,160\n",
            "       BatchNorm2d-7             [-1, 64, 8, 8]             128\n",
            "              ReLU-8             [-1, 64, 8, 8]               0\n",
            "         ConvBlock-9             [-1, 64, 8, 8]               0\n",
            "           Conv2d-10            [-1, 192, 8, 8]         110,784\n",
            "      BatchNorm2d-11            [-1, 192, 8, 8]             384\n",
            "             ReLU-12            [-1, 192, 8, 8]               0\n",
            "        ConvBlock-13            [-1, 192, 8, 8]               0\n",
            "        MaxPool2d-14            [-1, 192, 4, 4]               0\n",
            "           Conv2d-15             [-1, 64, 4, 4]          12,352\n",
            "      BatchNorm2d-16             [-1, 64, 4, 4]             128\n",
            "             ReLU-17             [-1, 64, 4, 4]               0\n",
            "        ConvBlock-18             [-1, 64, 4, 4]               0\n",
            "           Conv2d-19             [-1, 96, 4, 4]          18,528\n",
            "      BatchNorm2d-20             [-1, 96, 4, 4]             192\n",
            "             ReLU-21             [-1, 96, 4, 4]               0\n",
            "        ConvBlock-22             [-1, 96, 4, 4]               0\n",
            "           Conv2d-23            [-1, 128, 4, 4]         110,720\n",
            "      BatchNorm2d-24            [-1, 128, 4, 4]             256\n",
            "             ReLU-25            [-1, 128, 4, 4]               0\n",
            "        ConvBlock-26            [-1, 128, 4, 4]               0\n",
            "           Conv2d-27             [-1, 16, 4, 4]           3,088\n",
            "      BatchNorm2d-28             [-1, 16, 4, 4]              32\n",
            "             ReLU-29             [-1, 16, 4, 4]               0\n",
            "        ConvBlock-30             [-1, 16, 4, 4]               0\n",
            "           Conv2d-31             [-1, 32, 4, 4]          12,832\n",
            "      BatchNorm2d-32             [-1, 32, 4, 4]              64\n",
            "             ReLU-33             [-1, 32, 4, 4]               0\n",
            "        ConvBlock-34             [-1, 32, 4, 4]               0\n",
            "        MaxPool2d-35            [-1, 192, 4, 4]               0\n",
            "           Conv2d-36             [-1, 32, 4, 4]           6,176\n",
            "      BatchNorm2d-37             [-1, 32, 4, 4]              64\n",
            "             ReLU-38             [-1, 32, 4, 4]               0\n",
            "        ConvBlock-39             [-1, 32, 4, 4]               0\n",
            "  InceptionModule-40            [-1, 256, 4, 4]               0\n",
            "           Conv2d-41            [-1, 128, 4, 4]          32,896\n",
            "      BatchNorm2d-42            [-1, 128, 4, 4]             256\n",
            "             ReLU-43            [-1, 128, 4, 4]               0\n",
            "        ConvBlock-44            [-1, 128, 4, 4]               0\n",
            "           Conv2d-45            [-1, 128, 4, 4]          32,896\n",
            "      BatchNorm2d-46            [-1, 128, 4, 4]             256\n",
            "             ReLU-47            [-1, 128, 4, 4]               0\n",
            "        ConvBlock-48            [-1, 128, 4, 4]               0\n",
            "           Conv2d-49            [-1, 192, 4, 4]         221,376\n",
            "      BatchNorm2d-50            [-1, 192, 4, 4]             384\n",
            "             ReLU-51            [-1, 192, 4, 4]               0\n",
            "        ConvBlock-52            [-1, 192, 4, 4]               0\n",
            "           Conv2d-53             [-1, 32, 4, 4]           8,224\n",
            "      BatchNorm2d-54             [-1, 32, 4, 4]              64\n",
            "             ReLU-55             [-1, 32, 4, 4]               0\n",
            "        ConvBlock-56             [-1, 32, 4, 4]               0\n",
            "           Conv2d-57             [-1, 96, 4, 4]          76,896\n",
            "      BatchNorm2d-58             [-1, 96, 4, 4]             192\n",
            "             ReLU-59             [-1, 96, 4, 4]               0\n",
            "        ConvBlock-60             [-1, 96, 4, 4]               0\n",
            "        MaxPool2d-61            [-1, 256, 4, 4]               0\n",
            "           Conv2d-62             [-1, 64, 4, 4]          16,448\n",
            "      BatchNorm2d-63             [-1, 64, 4, 4]             128\n",
            "             ReLU-64             [-1, 64, 4, 4]               0\n",
            "        ConvBlock-65             [-1, 64, 4, 4]               0\n",
            "  InceptionModule-66            [-1, 480, 4, 4]               0\n",
            "        MaxPool2d-67            [-1, 480, 2, 2]               0\n",
            "           Conv2d-68            [-1, 192, 2, 2]          92,352\n",
            "      BatchNorm2d-69            [-1, 192, 2, 2]             384\n",
            "             ReLU-70            [-1, 192, 2, 2]               0\n",
            "        ConvBlock-71            [-1, 192, 2, 2]               0\n",
            "           Conv2d-72             [-1, 96, 2, 2]          46,176\n",
            "      BatchNorm2d-73             [-1, 96, 2, 2]             192\n",
            "             ReLU-74             [-1, 96, 2, 2]               0\n",
            "        ConvBlock-75             [-1, 96, 2, 2]               0\n",
            "           Conv2d-76            [-1, 208, 2, 2]         179,920\n",
            "      BatchNorm2d-77            [-1, 208, 2, 2]             416\n",
            "             ReLU-78            [-1, 208, 2, 2]               0\n",
            "        ConvBlock-79            [-1, 208, 2, 2]               0\n",
            "           Conv2d-80             [-1, 16, 2, 2]           7,696\n",
            "      BatchNorm2d-81             [-1, 16, 2, 2]              32\n",
            "             ReLU-82             [-1, 16, 2, 2]               0\n",
            "        ConvBlock-83             [-1, 16, 2, 2]               0\n",
            "           Conv2d-84             [-1, 48, 2, 2]          19,248\n",
            "      BatchNorm2d-85             [-1, 48, 2, 2]              96\n",
            "             ReLU-86             [-1, 48, 2, 2]               0\n",
            "        ConvBlock-87             [-1, 48, 2, 2]               0\n",
            "        MaxPool2d-88            [-1, 480, 2, 2]               0\n",
            "           Conv2d-89             [-1, 64, 2, 2]          30,784\n",
            "      BatchNorm2d-90             [-1, 64, 2, 2]             128\n",
            "             ReLU-91             [-1, 64, 2, 2]               0\n",
            "        ConvBlock-92             [-1, 64, 2, 2]               0\n",
            "  InceptionModule-93            [-1, 512, 2, 2]               0\n",
            "AdaptiveAvgPool2d-94            [-1, 512, 4, 4]               0\n",
            "           Conv2d-95            [-1, 128, 4, 4]          65,664\n",
            "             ReLU-96            [-1, 128, 4, 4]               0\n",
            "           Linear-97                 [-1, 1024]       2,098,176\n",
            "             ReLU-98                 [-1, 1024]               0\n",
            "          Dropout-99                 [-1, 1024]               0\n",
            "          Linear-100                   [-1, 10]          10,250\n",
            "    InceptionAux-101                   [-1, 10]               0\n",
            "          Conv2d-102            [-1, 160, 2, 2]          82,080\n",
            "     BatchNorm2d-103            [-1, 160, 2, 2]             320\n",
            "            ReLU-104            [-1, 160, 2, 2]               0\n",
            "       ConvBlock-105            [-1, 160, 2, 2]               0\n",
            "          Conv2d-106            [-1, 112, 2, 2]          57,456\n",
            "     BatchNorm2d-107            [-1, 112, 2, 2]             224\n",
            "            ReLU-108            [-1, 112, 2, 2]               0\n",
            "       ConvBlock-109            [-1, 112, 2, 2]               0\n",
            "          Conv2d-110            [-1, 224, 2, 2]         226,016\n",
            "     BatchNorm2d-111            [-1, 224, 2, 2]             448\n",
            "            ReLU-112            [-1, 224, 2, 2]               0\n",
            "       ConvBlock-113            [-1, 224, 2, 2]               0\n",
            "          Conv2d-114             [-1, 24, 2, 2]          12,312\n",
            "     BatchNorm2d-115             [-1, 24, 2, 2]              48\n",
            "            ReLU-116             [-1, 24, 2, 2]               0\n",
            "       ConvBlock-117             [-1, 24, 2, 2]               0\n",
            "          Conv2d-118             [-1, 64, 2, 2]          38,464\n",
            "     BatchNorm2d-119             [-1, 64, 2, 2]             128\n",
            "            ReLU-120             [-1, 64, 2, 2]               0\n",
            "       ConvBlock-121             [-1, 64, 2, 2]               0\n",
            "       MaxPool2d-122            [-1, 512, 2, 2]               0\n",
            "          Conv2d-123             [-1, 64, 2, 2]          32,832\n",
            "     BatchNorm2d-124             [-1, 64, 2, 2]             128\n",
            "            ReLU-125             [-1, 64, 2, 2]               0\n",
            "       ConvBlock-126             [-1, 64, 2, 2]               0\n",
            " InceptionModule-127            [-1, 512, 2, 2]               0\n",
            "          Conv2d-128            [-1, 128, 2, 2]          65,664\n",
            "     BatchNorm2d-129            [-1, 128, 2, 2]             256\n",
            "            ReLU-130            [-1, 128, 2, 2]               0\n",
            "       ConvBlock-131            [-1, 128, 2, 2]               0\n",
            "          Conv2d-132            [-1, 128, 2, 2]          65,664\n",
            "     BatchNorm2d-133            [-1, 128, 2, 2]             256\n",
            "            ReLU-134            [-1, 128, 2, 2]               0\n",
            "       ConvBlock-135            [-1, 128, 2, 2]               0\n",
            "          Conv2d-136            [-1, 256, 2, 2]         295,168\n",
            "     BatchNorm2d-137            [-1, 256, 2, 2]             512\n",
            "            ReLU-138            [-1, 256, 2, 2]               0\n",
            "       ConvBlock-139            [-1, 256, 2, 2]               0\n",
            "          Conv2d-140             [-1, 24, 2, 2]          12,312\n",
            "     BatchNorm2d-141             [-1, 24, 2, 2]              48\n",
            "            ReLU-142             [-1, 24, 2, 2]               0\n",
            "       ConvBlock-143             [-1, 24, 2, 2]               0\n",
            "          Conv2d-144             [-1, 64, 2, 2]          38,464\n",
            "     BatchNorm2d-145             [-1, 64, 2, 2]             128\n",
            "            ReLU-146             [-1, 64, 2, 2]               0\n",
            "       ConvBlock-147             [-1, 64, 2, 2]               0\n",
            "       MaxPool2d-148            [-1, 512, 2, 2]               0\n",
            "          Conv2d-149             [-1, 64, 2, 2]          32,832\n",
            "     BatchNorm2d-150             [-1, 64, 2, 2]             128\n",
            "            ReLU-151             [-1, 64, 2, 2]               0\n",
            "       ConvBlock-152             [-1, 64, 2, 2]               0\n",
            " InceptionModule-153            [-1, 512, 2, 2]               0\n",
            "          Conv2d-154            [-1, 112, 2, 2]          57,456\n",
            "     BatchNorm2d-155            [-1, 112, 2, 2]             224\n",
            "            ReLU-156            [-1, 112, 2, 2]               0\n",
            "       ConvBlock-157            [-1, 112, 2, 2]               0\n",
            "          Conv2d-158            [-1, 144, 2, 2]          73,872\n",
            "     BatchNorm2d-159            [-1, 144, 2, 2]             288\n",
            "            ReLU-160            [-1, 144, 2, 2]               0\n",
            "       ConvBlock-161            [-1, 144, 2, 2]               0\n",
            "          Conv2d-162            [-1, 288, 2, 2]         373,536\n",
            "     BatchNorm2d-163            [-1, 288, 2, 2]             576\n",
            "            ReLU-164            [-1, 288, 2, 2]               0\n",
            "       ConvBlock-165            [-1, 288, 2, 2]               0\n",
            "          Conv2d-166             [-1, 32, 2, 2]          16,416\n",
            "     BatchNorm2d-167             [-1, 32, 2, 2]              64\n",
            "            ReLU-168             [-1, 32, 2, 2]               0\n",
            "       ConvBlock-169             [-1, 32, 2, 2]               0\n",
            "          Conv2d-170             [-1, 64, 2, 2]          51,264\n",
            "     BatchNorm2d-171             [-1, 64, 2, 2]             128\n",
            "            ReLU-172             [-1, 64, 2, 2]               0\n",
            "       ConvBlock-173             [-1, 64, 2, 2]               0\n",
            "       MaxPool2d-174            [-1, 512, 2, 2]               0\n",
            "          Conv2d-175             [-1, 64, 2, 2]          32,832\n",
            "     BatchNorm2d-176             [-1, 64, 2, 2]             128\n",
            "            ReLU-177             [-1, 64, 2, 2]               0\n",
            "       ConvBlock-178             [-1, 64, 2, 2]               0\n",
            " InceptionModule-179            [-1, 528, 2, 2]               0\n",
            "AdaptiveAvgPool2d-180            [-1, 528, 4, 4]               0\n",
            "          Conv2d-181            [-1, 128, 4, 4]          67,712\n",
            "            ReLU-182            [-1, 128, 4, 4]               0\n",
            "          Linear-183                 [-1, 1024]       2,098,176\n",
            "            ReLU-184                 [-1, 1024]               0\n",
            "         Dropout-185                 [-1, 1024]               0\n",
            "          Linear-186                   [-1, 10]          10,250\n",
            "    InceptionAux-187                   [-1, 10]               0\n",
            "          Conv2d-188            [-1, 256, 2, 2]         135,424\n",
            "     BatchNorm2d-189            [-1, 256, 2, 2]             512\n",
            "            ReLU-190            [-1, 256, 2, 2]               0\n",
            "       ConvBlock-191            [-1, 256, 2, 2]               0\n",
            "          Conv2d-192            [-1, 160, 2, 2]          84,640\n",
            "     BatchNorm2d-193            [-1, 160, 2, 2]             320\n",
            "            ReLU-194            [-1, 160, 2, 2]               0\n",
            "       ConvBlock-195            [-1, 160, 2, 2]               0\n",
            "          Conv2d-196            [-1, 320, 2, 2]         461,120\n",
            "     BatchNorm2d-197            [-1, 320, 2, 2]             640\n",
            "            ReLU-198            [-1, 320, 2, 2]               0\n",
            "       ConvBlock-199            [-1, 320, 2, 2]               0\n",
            "          Conv2d-200             [-1, 32, 2, 2]          16,928\n",
            "     BatchNorm2d-201             [-1, 32, 2, 2]              64\n",
            "            ReLU-202             [-1, 32, 2, 2]               0\n",
            "       ConvBlock-203             [-1, 32, 2, 2]               0\n",
            "          Conv2d-204            [-1, 128, 2, 2]         102,528\n",
            "     BatchNorm2d-205            [-1, 128, 2, 2]             256\n",
            "            ReLU-206            [-1, 128, 2, 2]               0\n",
            "       ConvBlock-207            [-1, 128, 2, 2]               0\n",
            "       MaxPool2d-208            [-1, 528, 2, 2]               0\n",
            "          Conv2d-209            [-1, 128, 2, 2]          67,712\n",
            "     BatchNorm2d-210            [-1, 128, 2, 2]             256\n",
            "            ReLU-211            [-1, 128, 2, 2]               0\n",
            "       ConvBlock-212            [-1, 128, 2, 2]               0\n",
            " InceptionModule-213            [-1, 832, 2, 2]               0\n",
            "       MaxPool2d-214            [-1, 832, 1, 1]               0\n",
            "          Conv2d-215            [-1, 256, 1, 1]         213,248\n",
            "     BatchNorm2d-216            [-1, 256, 1, 1]             512\n",
            "            ReLU-217            [-1, 256, 1, 1]               0\n",
            "       ConvBlock-218            [-1, 256, 1, 1]               0\n",
            "          Conv2d-219            [-1, 160, 1, 1]         133,280\n",
            "     BatchNorm2d-220            [-1, 160, 1, 1]             320\n",
            "            ReLU-221            [-1, 160, 1, 1]               0\n",
            "       ConvBlock-222            [-1, 160, 1, 1]               0\n",
            "          Conv2d-223            [-1, 320, 1, 1]         461,120\n",
            "     BatchNorm2d-224            [-1, 320, 1, 1]             640\n",
            "            ReLU-225            [-1, 320, 1, 1]               0\n",
            "       ConvBlock-226            [-1, 320, 1, 1]               0\n",
            "          Conv2d-227             [-1, 32, 1, 1]          26,656\n",
            "     BatchNorm2d-228             [-1, 32, 1, 1]              64\n",
            "            ReLU-229             [-1, 32, 1, 1]               0\n",
            "       ConvBlock-230             [-1, 32, 1, 1]               0\n",
            "          Conv2d-231            [-1, 128, 1, 1]         102,528\n",
            "     BatchNorm2d-232            [-1, 128, 1, 1]             256\n",
            "            ReLU-233            [-1, 128, 1, 1]               0\n",
            "       ConvBlock-234            [-1, 128, 1, 1]               0\n",
            "       MaxPool2d-235            [-1, 832, 1, 1]               0\n",
            "          Conv2d-236            [-1, 128, 1, 1]         106,624\n",
            "     BatchNorm2d-237            [-1, 128, 1, 1]             256\n",
            "            ReLU-238            [-1, 128, 1, 1]               0\n",
            "       ConvBlock-239            [-1, 128, 1, 1]               0\n",
            " InceptionModule-240            [-1, 832, 1, 1]               0\n",
            "          Conv2d-241            [-1, 384, 1, 1]         319,872\n",
            "     BatchNorm2d-242            [-1, 384, 1, 1]             768\n",
            "            ReLU-243            [-1, 384, 1, 1]               0\n",
            "       ConvBlock-244            [-1, 384, 1, 1]               0\n",
            "          Conv2d-245            [-1, 192, 1, 1]         159,936\n",
            "     BatchNorm2d-246            [-1, 192, 1, 1]             384\n",
            "            ReLU-247            [-1, 192, 1, 1]               0\n",
            "       ConvBlock-248            [-1, 192, 1, 1]               0\n",
            "          Conv2d-249            [-1, 384, 1, 1]         663,936\n",
            "     BatchNorm2d-250            [-1, 384, 1, 1]             768\n",
            "            ReLU-251            [-1, 384, 1, 1]               0\n",
            "       ConvBlock-252            [-1, 384, 1, 1]               0\n",
            "          Conv2d-253             [-1, 48, 1, 1]          39,984\n",
            "     BatchNorm2d-254             [-1, 48, 1, 1]              96\n",
            "            ReLU-255             [-1, 48, 1, 1]               0\n",
            "       ConvBlock-256             [-1, 48, 1, 1]               0\n",
            "          Conv2d-257            [-1, 128, 1, 1]         153,728\n",
            "     BatchNorm2d-258            [-1, 128, 1, 1]             256\n",
            "            ReLU-259            [-1, 128, 1, 1]               0\n",
            "       ConvBlock-260            [-1, 128, 1, 1]               0\n",
            "       MaxPool2d-261            [-1, 832, 1, 1]               0\n",
            "          Conv2d-262            [-1, 128, 1, 1]         106,624\n",
            "     BatchNorm2d-263            [-1, 128, 1, 1]             256\n",
            "            ReLU-264            [-1, 128, 1, 1]               0\n",
            "       ConvBlock-265            [-1, 128, 1, 1]               0\n",
            " InceptionModule-266           [-1, 1024, 1, 1]               0\n",
            "AdaptiveAvgPool2d-267           [-1, 1024, 1, 1]               0\n",
            "         Dropout-268                 [-1, 1024]               0\n",
            "          Linear-269                   [-1, 10]          10,250\n",
            "================================================================\n",
            "Total params: 10,348,590\n",
            "Trainable params: 10,348,590\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 2.67\n",
            "Params size (MB): 39.48\n",
            "Estimated Total Size (MB): 42.16\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Iy7e81D6Cd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zYLT95o6CeN",
        "colab_type": "text"
      },
      "source": [
        "## c) Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBkLVkjl6CeQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model():\n",
        "    EPOCHS = 20\n",
        "    nb_examples = 45000\n",
        "    nb_val_examples = 5000\n",
        "    train_costs, val_costs = [], []\n",
        "    \n",
        "    #Training phase.\n",
        "    \n",
        "    for epoch in range(EPOCHS):\n",
        "\n",
        "        train_loss = 0\n",
        "        correct_train = 0\n",
        "        \n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            # Zero the parameter gradients.\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass.\n",
        "            prediction0, prediction1, prediction2 = model(inputs)\n",
        "            \n",
        "            # Compute the loss.\n",
        "            loss0 = criterion(prediction0, labels)\n",
        "            loss1 = criterion(prediction1, labels)\n",
        "            loss2 = criterion(prediction2, labels)\n",
        "            \n",
        "            loss = loss0 + 0.3 * loss1 + 0.3 * loss2\n",
        "            \n",
        "            # Backward pass.\n",
        "            loss.backward()\n",
        "            \n",
        "            # Optimize.\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Compute training accuracy.\n",
        "            _, predicted = torch.max(prediction0.data, 1)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "            \n",
        "            # Compute batch loss.\n",
        "            train_loss += (loss.data.item() * inputs.shape[0])\n",
        "\n",
        "\n",
        "        train_loss /= nb_examples\n",
        "        train_costs.append(train_loss)\n",
        "        train_acc =  correct_train / nb_examples\n",
        "\n",
        "        val_loss = 0\n",
        "        correct_val = 0\n",
        "\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients.\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass.\n",
        "            prediction0, prediction1, prediction2 = model(inputs)\n",
        "            \n",
        "            # Compute the loss.\n",
        "            loss0 = criterion(prediction0, labels)\n",
        "            loss1 = criterion(prediction1, labels)\n",
        "            loss2 = criterion(prediction2, labels)\n",
        "            \n",
        "            loss = loss0 + 0.3 * loss1 + 0.3 * loss2\n",
        "            \n",
        "            # Backward pass.\n",
        "            loss.backward()\n",
        "            \n",
        "            # Optimize.\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Compute training accuracy.\n",
        "            _, predicted = torch.max(prediction0.data, 1)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "            \n",
        "             # Compute batch loss.\n",
        "            val_loss += (loss.data.item() * inputs.shape[0])\n",
        "\n",
        "        val_loss /= nb_val_examples\n",
        "        val_costs.append(val_loss)\n",
        "        val_acc =  correct_val / nb_val_examples\n",
        "        \n",
        "        info = \"[Epoch {}/{}]: train-loss = {:0.6f} | train-acc = {:0.3f} | val-loss = {:0.6f} | val-acc = {:0.3f}\"\n",
        "        print(info.format(epoch+1, EPOCHS, train_loss, train_acc, val_loss, val_acc))\n",
        "        torch.save(model.state_dict(), 'save_weights/googlenet_model_{}'.format(epoch + 1)) \n",
        "                                                                \n",
        "    torch.save(model.state_dict(), 'googlenet_model_final')  \n",
        "        \n",
        "    return train_costs, val_costs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxT7jmjb6Cea",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "07a525f7-96ee-4563-a8e4-f319f2018cf8"
      },
      "source": [
        "train_costs, val_costs = train_model()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 1/20]: train-loss = 3.337094 | train-acc = 0.220 | val-loss = 2.802224 | val-acc = 0.325\n",
            "[Epoch 2/20]: train-loss = 2.557571 | train-acc = 0.387 | val-loss = 2.335853 | val-acc = 0.440\n",
            "[Epoch 3/20]: train-loss = 2.191851 | train-acc = 0.489 | val-loss = 1.969647 | val-acc = 0.549\n",
            "[Epoch 4/20]: train-loss = 1.932995 | train-acc = 0.556 | val-loss = 1.746358 | val-acc = 0.605\n",
            "[Epoch 5/20]: train-loss = 1.729847 | train-acc = 0.611 | val-loss = 1.530364 | val-acc = 0.658\n",
            "[Epoch 6/20]: train-loss = 1.507906 | train-acc = 0.665 | val-loss = 1.297369 | val-acc = 0.717\n",
            "[Epoch 7/20]: train-loss = 1.319329 | train-acc = 0.711 | val-loss = 1.151064 | val-acc = 0.749\n",
            "[Epoch 8/20]: train-loss = 1.223894 | train-acc = 0.732 | val-loss = 0.997665 | val-acc = 0.787\n",
            "[Epoch 9/20]: train-loss = 1.069085 | train-acc = 0.766 | val-loss = 0.834602 | val-acc = 0.821\n",
            "[Epoch 10/20]: train-loss = 0.989535 | train-acc = 0.784 | val-loss = 0.746914 | val-acc = 0.845\n",
            "[Epoch 11/20]: train-loss = 0.828136 | train-acc = 0.825 | val-loss = 0.584873 | val-acc = 0.882\n",
            "[Epoch 12/20]: train-loss = 0.705851 | train-acc = 0.851 | val-loss = 0.487400 | val-acc = 0.904\n",
            "[Epoch 13/20]: train-loss = 0.581230 | train-acc = 0.876 | val-loss = 0.390852 | val-acc = 0.916\n",
            "[Epoch 14/20]: train-loss = 0.508664 | train-acc = 0.894 | val-loss = 0.374233 | val-acc = 0.920\n",
            "[Epoch 15/20]: train-loss = 0.525554 | train-acc = 0.891 | val-loss = 0.344252 | val-acc = 0.929\n",
            "[Epoch 16/20]: train-loss = 0.459459 | train-acc = 0.904 | val-loss = 0.284896 | val-acc = 0.941\n",
            "[Epoch 17/20]: train-loss = 0.366622 | train-acc = 0.924 | val-loss = 0.223688 | val-acc = 0.958\n",
            "[Epoch 18/20]: train-loss = 0.339363 | train-acc = 0.930 | val-loss = 0.183352 | val-acc = 0.960\n",
            "[Epoch 19/20]: train-loss = 0.271985 | train-acc = 0.944 | val-loss = 0.161323 | val-acc = 0.967\n",
            "[Epoch 20/20]: train-loss = 0.263724 | train-acc = 0.944 | val-loss = 0.165356 | val-acc = 0.968\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STo-5WyWQk9_",
        "colab_type": "text"
      },
      "source": [
        "## d) Evaluating model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEdPAaaIQoRW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "2ff50d94-0d28-4b87-ec9d-448ba89a2a3e"
      },
      "source": [
        "# Restore the model.\n",
        "model = GoogLeNet(isTraining=False)\n",
        "load_model('googlenet_model_final', model)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-2a0efc2a075e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogLeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misTraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'googlenet_model_final'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/utils.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(pretrained_model_file, target_model)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpretrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mnew_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_key\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mnew_state_dict_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMOvxjEKQyWv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create iterator.\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# Make predictions.\n",
        "predictions = model(images)\n",
        "\n",
        "# Retrieve predictions indexes.\n",
        "_, predicted = torch.max(predictions, 1)\n",
        "\n",
        "# Compute number of correct predictions.\n",
        "correct = (predicted == labels).sum().item()\n",
        "\n",
        "# Compute accuracy on test set.\n",
        "test_accuracy = correct / images.shape[0]\n",
        "print('Test set error rate: {}'.format(test_accuracy))\n",
        "\n",
        "# Plot some examples with model predictions.\n",
        "print('\\nSome correct classification:')\n",
        "plot_example(images.numpy(), labels.numpy(), predicted.numpy())\n",
        "\n",
        "print('\\nSome incorrect classification:')\n",
        "plot_example_errors(images.numpy(), labels.numpy(), predicted.numpy())\n",
        "\n",
        "# Plot training error.\n",
        "print('\\nPlot of training/validation error over 20 epochs:')\n",
        "plt.title('Training/Validation error')\n",
        "plt.ylabel('Cost')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.plot(train_costs)\n",
        "plt.plot(val_costs)\n",
        "plt.legend(['train-loss', 'val-loss'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}