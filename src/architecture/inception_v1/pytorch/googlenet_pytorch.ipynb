{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I) Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The paper [Going Deeper with Convolutions][paper] introduces the first version of Inception model called GoogLeNet.\n",
    "\n",
    "\n",
    "- During ILSVLC-2014, they achieved 1st place at the classification task (top-5 test error = 6.67%)\n",
    "\n",
    "\n",
    "- It has around 6.7977 million parameters which is 9x fewer than AlexNet (ILSVRC-2012 winner) and 20x fewer than its competitor VGG-16.\n",
    "\n",
    "\n",
    "- In most of the standard network architectures, the intuition is not clear why and when to perform the max-pooling operation, when to use the convolutional operation. For example, in AlextNet we have the convolutional operation and max-pooling operation following each other whereas in VGGNet, we have 3 convolutional operations in a row and then 1 max-pooling layer.\n",
    "\n",
    "\n",
    "- Thus, **the idea behind GoogLeNet is to use all the operations at the same time**. It computes multiple kernels of different size over the same input map in parallel, concatenating their results into a single output. This is called an **Inception module**.\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"https://cdn.discordapp.com/attachments/676833120053493770/689776141221101629/unknown.png\"\n",
    "         height=\"100%\" width=\"100%\">\n",
    "</div>\n",
    "\n",
    "- Consider the following:\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"https://media.discordapp.net/attachments/676833120053493770/690136206092402715/unknown.png\"\n",
    "         height=\"50%\" width=\"70%\">\n",
    "</div>\n",
    " \n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"https://cdn.discordapp.com/attachments/676833120053493770/690138280058028146/unknown.png\"\n",
    "         height=\"50%\" width=\"90%\">\n",
    "</div>\n",
    "\n",
    "\n",
    "- The Naive approach is computationally expensive:\n",
    "    - Computation cost = ((28 x 28 x 5 x 5) x 192) x 32 $\\simeq$ **120 Mil**\n",
    "        - We perform (28 x 28 x 5 x 5) operations along 192 channels for each of the 32 filters.\n",
    "\n",
    "\n",
    "- The dimension reduction approach is **less** computationally expensive:\n",
    "    - 1st layer computation cost = ((28 x 28 x 1 x 1) x 192) x 16 $\\simeq$ 2.4 Mil\n",
    "    - 2nd layer computation cost = ((28 x 28 x 5 x 5) x 16) x 32 $\\simeq$ 10 Mil  \n",
    "    - Total computation cost $\\simeq$ **12.4 Mil**\n",
    "\n",
    "---\n",
    "\n",
    "Here its architecture:\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"https://cdn.discordapp.com/attachments/676833120053493770/690150147392667651/unknown.png\"\n",
    "         height=\"100%\" width=\"100%\">\n",
    "</div>\n",
    "\n",
    "- There are:\n",
    "    - 9 Inception modules (red box)\n",
    "    - 2 auxilaries softmax layer (green box)\n",
    "        - Their role is to push the network toward its goal and helps to ensure that the intermediate features are good enough for the network to learn.\n",
    "        - It turns out that softmax0 and sofmax1 gives regularization effect.\n",
    "        - They are ignored during inference.\n",
    "    - Global Average pooling were used instead of a Fully-connected layer.\n",
    "        - It enables adapting and fine-tuning on the network easily.\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"https://cdn.discordapp.com/attachments/676833120053493770/690147584534511659/unknown.png\"\n",
    "         height=\"100%\" width=\"80%\">\n",
    "</div>\n",
    "\n",
    "[paper]: https://arxiv.org/pdf/1409.4842.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II) Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
