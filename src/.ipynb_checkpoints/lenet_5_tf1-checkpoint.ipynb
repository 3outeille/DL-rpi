{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I) Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DISCLAIMER**: We will use a simplier version of the LeNet-5 than the one in the [paper](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf). (For example, computation on average pooling layers described in the paper are slightly more complex than usual)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet-5 has:\n",
    "\n",
    "- 2 Convolutional layers.\n",
    "- 3 Fully connected layers.\n",
    "- 2 Average pooling layers.\n",
    "- Tanh as activation function for hidden layer.\n",
    "- Softmax as activation function for output layer.\n",
    "- 60000 trainable parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet-5 is:\n",
    "\n",
    "- trained on MNIST dataset (60000 training examples).\n",
    "- trained over 20 epoch.\n",
    "- expected to converge after 10-12 epoch.\n",
    "- expected to have an error rate of 0.95% on test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II) Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a) Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "Image Shape: (28, 28, 1)\n",
      "\n",
      "Training Set:   55000 samples\n",
      "Validation Set: 5000 samples\n",
      "Test Set:       10000 samples\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"data/MNIST\", reshape=False)\n",
    "X_train, y_train           = mnist.train.images, mnist.train.labels\n",
    "X_val, y_val = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test             = mnist.test.images, mnist.test.labels\n",
    "\n",
    "print()\n",
    "print(\"Image Shape: {}\".format(X_train[0].shape), end = '\\n\\n')\n",
    "print(\"Training Set:   {} samples\".format(len(X_train)))\n",
    "print(\"Validation Set: {} samples\".format(len(X_val)))\n",
    "print(\"Test Set:       {} samples\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to:\n",
    "\n",
    "- reshape the image into a 32x32x1 shape.\n",
    "- normalize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Image Shape for: \n",
      "\n",
      "-Training set: (55000, 32, 32, 1)\n",
      "-Validation set: (5000, 32, 32, 1)\n",
      "-Test set: (10000, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Pad images with 0s\n",
    "X_train = np.pad(X_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_val = np.pad(X_val, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_test = np.pad(X_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "\n",
    "print(\"Updated Image Shape for: \", end='\\n\\n')\n",
    "print(\"-Training set: {}\".format(X_train.shape))\n",
    "print(\"-Validation set: {}\".format(X_val.shape))\n",
    "print(\"-Test set: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization.\n",
    "X_train, X_test = X_train/float(255), X_test/float(255)\n",
    "X_train -= np.mean(X_train)\n",
    "X_test -= np.mean(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) Vizualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit on the image: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = X_train[0, :, :, 0]\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "print('Digit on the image: ' + str(y_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d) Architecture build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders():\n",
    "    \"\"\"\n",
    "        Creates the placeholders for the tensorflow session.\n",
    "        \n",
    "        Returns:\n",
    "        -X: placeholder for the data input of shape [None, 32, 32, 1] and dtype \"float\".\n",
    "        -y: placeholder for the input labels of shape [None] and dtype \"float\".\n",
    "    \"\"\"\n",
    "    X = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "    y = tf.placeholder(tf.int32, (None))\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "        Initializes weights and biases parameters using xavier initialization.\n",
    "        \n",
    "        Returns:\n",
    "        -parameters: A dictionary of tensors containing the weights and biases. \n",
    "    \"\"\"\n",
    "    \n",
    "    C1_w = tf.get_variable(\"C1_w\",shape = [5,5,1,6], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    C2_w = tf.get_variable(\"C2_w\",shape = [5,5,6,16], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    F1_w = tf.get_variable(\"F1_w\",shape = [120,400], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    F2_w = tf.get_variable(\"F2_w\",shape = [84,120], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    F3_w = tf.get_variable(\"F3_w\",shape = [10,84], initializer = tf.contrib.layers.xavier_initializer())\n",
    "    \n",
    "    C1_b = tf.get_variable(\"C1_b\", shape = [6], initializer = tf.zeros_initializer())\n",
    "    C2_b = tf.get_variable(\"C2_b\", shape = [16], initializer = tf.zeros_initializer())\n",
    "    F1_b = tf.get_variable(\"F1_b\", shape = [120], initializer = tf.zeros_initializer())\n",
    "    F2_b = tf.get_variable(\"F2_b\", shape = [84], initializer = tf.zeros_initializer())\n",
    "    F3_b = tf.get_variable(\"F3_b\", shape = [10], initializer = tf.zeros_initializer())\n",
    "    \n",
    "    paremeters = {'C1_w': C1_w, 'C1_b': C1_b,\n",
    "                  'C2_w': C2_w, 'C2_b': C2_b,\n",
    "                  'F1_w': F1_w, 'F1_b': F1_b,\n",
    "                  'F2_w': F2_w, 'F2_b': F2_b,\n",
    "                  'F3_w': F3_w, 'F3_b': F3_b}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def LeNet_5(X):\n",
    "    \n",
    "    #Create placeholders.\n",
    "    X, y = create_placeholders()\n",
    "    \n",
    "    #Intialize parameters.\n",
    "    parameters = initialize_parameters()\n",
    "    \n",
    "    #Forward propagation.\n",
    "    #(None,32,32,1) -> (None,28,28,6).\n",
    "    C1 = tf.nn.conv2d(X, parameters['C1_w'], strides=[1,1,1,1], padding='SAME') + parameters['C1_b']\n",
    "    A1 = tf.nn.tanh(C1)\n",
    "    #(None,28,28,6) -> (None,14,14,6).\n",
    "    P1 = tf.nn.avg_pool(A1, ksize=(6,2,2,1), strides = (6,2,2,1), padding='SAME')\n",
    "    \n",
    "    #(None,14,14,6) -> (None,10,10,16).\n",
    "    C2 = tf.nn.conv2d(P1, parameters['C2_w'], strides=[1,1,1,1], padding='SAME') + parameters['C2_b']\n",
    "    A2 = tf.nn.tanh(C2)\n",
    "    #(None,10,10,16) -> (None,5,5,16).\n",
    "    P2 = tf.nn.avg_pool(A2, ksize=(16,2,2,1), strides = (16,2,2,1), padding='SAME')\n",
    "    \n",
    "    #(None,5,5,16) -> (None, 400, 1).\n",
    "    P2_flatten = tf.contrib.layers.flatten(P2)\n",
    "    \n",
    "    #(None, 400,1) -> (None,120,1).\n",
    "    F1 = tf.matmul(P2_flatten, parameters['F1_w']) + parameters['F1_b']\n",
    "    A3 = tf.nn.tanh(F1)\n",
    "    \n",
    "    #(None,120,1) -> (None,84,1).\n",
    "    F2 = tf.matmul(A3, parameters['F2_w']) + parameters['F2_b']\n",
    "    A4 = tf.nn.tanh(F2)\n",
    "    \n",
    "    #(None,84,1) -> (None,10,1)\n",
    "    F3 = tf.matmul(A4, parameters['F3_w']) + parameters['F3_b']\n",
    "    \n",
    "    #Loss function.\n",
    "    lr = 0.001\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits = F3, labels = tf.one_hot(y, 10))\n",
    "    loss_operation = tf.reduce_mean(cross_entropy)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = lr)\n",
    "    training_operation = optimizer.minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III) Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-tf1.14",
   "language": "python",
   "name": "dl-tf1.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
